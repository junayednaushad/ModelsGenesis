{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import nrrd\n",
    "import sys\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "plt.style.use('seaborn-dark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(data_dir, filename, filetype):\n",
    "    img, _ = nrrd.read(os.path.join(data_dir, '{}_{}.nrrd'.format(filename, filetype)))\n",
    "    # img = img.astype(np.float32)\n",
    "    img = img.transpose(1,2,0)\n",
    "    return img\n",
    "\n",
    "def normalize(img, minimum=-1000, maximum=1000):\n",
    "    img = copy.deepcopy(img)\n",
    "    img[img > maximum] = maximum\n",
    "    img[img < minimum] = minimum\n",
    "    img = (img - minimum) / max(1, (maximum - minimum))\n",
    "    return img\n",
    "\n",
    "def save_subvolumes(img, masks, save_dir, filename, h=64, w=64, d=64):\n",
    "    \n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    H, W, D = img.shape\n",
    "    for x in range(0, H, h):\n",
    "        end_x = min(x+h, H)\n",
    "        start_x = end_x - h\n",
    "        for y in range(0, W, w):\n",
    "            end_y = min(y+w, W)\n",
    "            start_y = end_y - w\n",
    "            for z in range(0, D, d):\n",
    "                end_z = min(z+d, D)\n",
    "                start_z = end_z - d\n",
    "\n",
    "                subvolume = img[np.newaxis, start_x:end_x, start_y:end_y, start_z:end_z]\n",
    "                mask_subvolume = np.concatenate([arr[np.newaxis, start_x:end_x, start_y:end_y, start_z:end_z] for arr in masks], axis=0)\n",
    "                np.save(os.path.join(save_path, '{}_{}_{}_{}.npy'.format(filename, start_x, start_y, start_z)), \n",
    "                        {'image':subvolume, 'label':mask_subvolume})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_dir = '/media/hdd10tb/xiangyiy/data/preprocessed'\n",
    "roi_names = ['Large Bowel',\n",
    "            'Duodenum', \n",
    "            'Spinal Cord',\n",
    "            'Liver',\n",
    "            'Spleen',\n",
    "            'Small Bowel',\n",
    "            'Pancreas',\n",
    "            'Kidney L',\n",
    "            'Kidney R',\n",
    "            'Stomach',\n",
    "            'Gallbladder']\n",
    "roi_names.sort()\n",
    "\n",
    "save_dir = '/media/hdd10tb/junayedn/private_abdomen/3d_preprocessed'\n",
    "train_filenames = pd.read_csv('/home/junayedn/ModelsGenesis/pytorch/split/abdomen_train_superpixel_10.csv')['eid'].values\n",
    "val_filenames = pd.read_csv('/home/junayedn/ModelsGenesis/pytorch/split/abdomen_val.csv')['eid'].values\n",
    "filenames = list(train_filenames) + list(val_filenames)\n",
    "\n",
    "for f in filenames:\n",
    "    img = load_img(finetune_dir, f, 'clean')\n",
    "    img = normalize(img)\n",
    "    masks = []\n",
    "    for roi in roi_names:\n",
    "        if not os.path.exists(os.path.join(finetune_dir, '{}_{}.nrrd'.format(f, roi))):\n",
    "            masks.append(np.zeros(img.shape).astype(np.uint8))\n",
    "        else:\n",
    "            masks.append(load_img(finetune_dir, f, roi))\n",
    "    save_subvolumes(img, masks, save_dir, f, h=160, w=160, d=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172 268 100\n",
      "316 508 333\n"
     ]
    }
   ],
   "source": [
    "min_h = 100000\n",
    "min_w = 100000\n",
    "min_d = 100000\n",
    "\n",
    "max_h = 0\n",
    "max_w = 0\n",
    "max_d = 0\n",
    "\n",
    "img_nums= [f.split('_')[0] for f in os.listdir('/media/hdd10tb/xiangyiy/data/preprocessed') if '_clean' in f]\n",
    "for f in img_nums:\n",
    "    img = load_img('/media/hdd10tb/xiangyiy/data/preprocessed', f, 'clean')\n",
    "    h,w,d = img.shape\n",
    "    \n",
    "    if h < min_h:\n",
    "        min_h = h\n",
    "    if h > max_h:\n",
    "        max_h = h\n",
    "\n",
    "    if w < min_w:\n",
    "        min_w = w\n",
    "    if w > max_w:\n",
    "        max_w = w\n",
    "\n",
    "    if d < min_d:\n",
    "        min_d = d\n",
    "    if d > max_d:\n",
    "        max_d = d\n",
    "\n",
    "print(min_h, min_w, min_d)\n",
    "print(max_h, max_w, max_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665\n"
     ]
    }
   ],
   "source": [
    "num_files = 0\n",
    "for eid in os.listdir(save_dir):\n",
    "    num_files += len(os.listdir(os.path.join(save_dir, eid)))\n",
    "print(num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a9f8bd3b2289ebb2b6e403df85544ce4353d3d44338fdb7e5d7f535d9df122f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
